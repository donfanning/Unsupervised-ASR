dirs:
    train:
        data: /home/user/easton/data/AISHELL/train_phone_9k.csv
        # data: /home/user/easton/data/AISHELL/tfdata/train_39/1.csv
        tfdata: /home/user/easton/data/AISHELL/tfdata/train_9k
    dev:
        data: /home/user/easton/data/AISHELL/test_phone_67.csv
        tfdata: /home/user/easton/data/AISHELL/tfdata/dev_67
    test:
        data: /home/user/easton/data/AISHELL/test_phone_67.csv
    type: csv
    vocab: /home/user/easton/data/AISHELL/phones_67.txt
    ngram: /home/user/easton/projects/EODM/data/5k_67.ngram
    # ngram: /home/user/easton/projects/EODM/data/5k_4gram_67.ngram
    # ngram: /home/user/easton/projects/EODM/data/5k_67.2gram
    # ngram: /home/user/easton/projects/EODM/data/9k_67.4gram
    # ngram: /home/user/easton/projects/EODM/data/9k_67.3gram
    restore: /home/user/easton/projects/EODM/models/aishell_phone_9k/checkpoint_supervised/

data:
    featType: fbank
    dim_raw_input: 13
    num_context: 10
    downsample: 3
    add_delta: False
    unit: phone
    full_align: True
    ngram: 5
    top_k: 1000
    k: 1000

model:
    structure: fc
    training_type: teacher-forcing
    loss_type: CE
    num_hidden: 128
    num_layers: 1

opti:
    type: adam
    warmup_steps: 10
    peak: 0.0005
    decay_steps: 1000
    beam_size: 1
    # beam_size: 50
    num_threads: 8

dev_step: 100
decode_step: 50
save_step: 5

gpus: '1'
# gpus: '0,1,2,3'
num_batch_tokens: 120000
batch_size: 2700
# batch_size: 1000
bucket_boundaries: 81,91,101,111,122,134,149,169,224,363,1000

num_epochs: 100000
num_steps: 500000

length_penalty_weight: 0.0
l1: 0.1
l2: 0.1
lambda_fs: 0.00001

grad_clip_global_norm: 0.0
